The formal algorithm remains brutally effective. Given a set of events and their calculated impacts, it performs a single task:

1.  **Sort:** Events are sorted by impact in descending order.
2.  **Accumulate:** The algorithm moves down the list, summing the impacts.
3.  **Identify:** It stops as soon as the accumulated sum reaches a defined threshold (e.g., 80%) of the total impact.

The output is not a complex model, but a simple, actionable list of the critical few. This is the system's pressure pointâ€”the place where the least effort will produce the greatest healing.

```python
def reverse_pareto_analysis(events, impacts, threshold=0.8):
    """
    Identifies the smallest subset of events that accounts for at least
    `threshold` of the total impact.
    """
    if not impacts or not events:
        return [], 0.0

    paired_events = sorted(zip(events, impacts), key=lambda p: p[1], reverse=True)
    total_impact = sum(impacts)
    if total_impact == 0:
        return [], 0.0
    
    target_impact = threshold * total_impact
    
    accumulated_impact = 0.0
    critical_few = []
    
    for event, impact in paired_events:
        if accumulated_impact >= target_impact:
            break
        critical_few.append(event)
        accumulated_impact += impact
        
    return critical_few, accumulated_impact / total_impact
```