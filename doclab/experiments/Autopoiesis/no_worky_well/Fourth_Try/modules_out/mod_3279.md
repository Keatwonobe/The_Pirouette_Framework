import numpy as np
import json
import os
import re
import tkinter as tk
from tkinter import filedialog, scrolledtext
import urllib.request
from urllib.parse import urlparse
from scipy.ndimage import convolve
from scipy.signal import welch
import math
import threading
import traceback
from bs4 import BeautifulSoup

# --- Configuration ---
GRID_SIZE = 64
NUM_FRAMES = 200
NOISE_LEVEL = 0.05
EVOLUTION_KERNEL = np.ones((3, 3)) / 9.0
PERTURBATION_AMPLITUDE = 0.01

# --- The Calibration & Analysis Sets ---
GEOMETRIC_PATTERNS = ["point", "line", "circle"]
SEMANTIC_DICTIONARY = ["love", "hate", "fear", "courage", "truth", "lie", "order", "chaos"]

def set_seed(s=None):
    """Sets the random seed for numpy for reproducibility."""
    np.random.seed(None if s is None else s)

class SemanticDistillator:
    """
    Handles the core logic of semantic analysis and the new diagnostic drills.
    """
    def __init__(self, logger=print):
        self.logger = logger
        set_seed(0) # Set a default seed for consistent base static field
        self.base_static_field = np.random.rand(GRID_SIZE, GRID_SIZE) * NOISE_LEVEL

    def text_to_binary_image(self, text, width, height):
        """Converts a string of text into a binary image (numpy array)."""
        binary_string = ''.join(format(ord(char), '08b') for char in text)
        binary_array = np.array([int(bit) for bit in binary_string], dtype=np.float32)
        target_size = width * height
        if len(binary_array) > target_size:
            binary_array = binary_array[:target_size]
        else:
            padding = np.zeros(target_size - len(binary_array))
            binary_array = np.concatenate([binary_array, padding])
        return binary_array.reshape((width, height))

    def generate_geometric_pattern(self, shape_name, grid_size):
        """Generates a binary pattern for a given geometric shape."""
        pattern = np.zeros((grid_size, grid_size), dtype=np.float32)
        center = grid_size // 2
        if shape_name == "point":
            pattern[center, center] = 1.0
        elif shape_name == "line":
            pattern[:, center] = 1.0
        elif shape_name == "circle":
            radius = grid_size // 4
            y, x = np.ogrid[-center:grid_size-center, -center:grid_size-center]
            mask = x*x + y*y <= radius*radius
            pattern[mask] = 1.0
        return pattern

    def _run_simulation_and_get_fingerprint(self, base_field, perturbation_pattern):
        """Internal method to run simulation with a specified base field."""
        field = base_field.copy()
        time_series = []
        for _ in range(NUM_FRAMES):
            field += perturbation_pattern * PERTURBATION_AMPLITUDE
            field = convolve(field, EVOLUTION_KERNEL, mode='wrap')
            time_series.append(np.mean(field))
        
        frequencies, psd = welch(np.array(time_series), fs=1.0, nperseg=min(len(time_series), 256))
        
        if len(psd) == 0 or np.sum(psd) == 0:
            return {'dominant_frequency': 0.0, 'total_power': 0.0}

        return {
            'dominant_frequency': float(frequencies[np.argmax(psd)]),
            'total_power': float(np.sum(psd))
        }

    def get_resonant_fingerprint(self, perturbation_pattern):
        """Runs one simulation using the instance's default base_static_field."""
        return self._run_simulation_and_get_fingerprint(self.base_static_field, perturbation_pattern)

    # --- Main Analysis Method ---
    def run_analysis(self, document_text, input_source_name, sentences_per_group=10):
        """Executes the full distillation process using grouped-sentence analysis."""
        # This function remains the same as the previous version
        self.logger("Initializing Semantic Distillation Engine...")
        self.logger(f"Analyzing source: {input_source_name}")
        self.logger(f"Using a group size of {sentences_per_group} sentences.")
        full_results = {}
        self.logger("\n--- Phase 1: Running Calibration Suite ---")
        calibration_results = {"geometric": {}, "semantic": {}}
        for shape in GEOMETRIC_PATTERNS:
            pattern = self.generate_geometric_pattern(shape, GRID_SIZE)
            calibration_results["geometric"][shape] = self.get_resonant_fingerprint(pattern)
        for word in SEMANTIC_DICTIONARY:
            pattern = self.text_to_binary_image(word, GRID_SIZE, GRID_SIZE)
            calibration_results["semantic"][word] = self.get_resonant_fingerprint(pattern)
        full_results['calibration_baselines'] = calibration_results
        self.logger(f"\n--- Phase 2: Performing Grouped Analysis ---")
        all_sentences = [s.strip() for s in re.split(r'[.?!]\s+', document_text) if s.strip()]
        if not all_sentences:
            self.logger("Error: No sentences found in the document.")
            return None
        num_groups = math.ceil(len(all_sentences) / sentences_per_group)
        self.logger(f"Document split into {len(all_sentences)} sentences, forming {num_groups} groups.")
        distillation_by_group = []
        total_distilled_power = 0
        for i in range(num_groups):
            start_index = i * sentences_per_group
            end_index = start_index + sentences_per_group
            sentence_group = all_sentences[start_index:end_index]
            self.logger(f"  - Processing Group {i+1}/{num_groups}...")
            holistic_group_text = " ".join(sentence_group)
            holistic_pattern = self.text_to_binary_image(holistic_group_text, GRID_SIZE, GRID_SIZE)
            holistic_fingerprint = self.get_resonant_fingerprint(holistic_pattern)
            chunked_fingerprints = [self.get_resonant_fingerprint(self.text_to_binary_image(c, GRID_SIZE, GRID_SIZE)) for c in sentence_group]
            aggregated_power = np.sum([fp['total_power'] for fp in chunked_fingerprints])
            group_delta = holistic_fingerprint['total_power'] - aggregated_power
            total_distilled_power += group_delta
            distillation_by_group.append({
                "group_index": i,
                "sentences": sentence_group,
                "holistic_group_fingerprint": holistic_fingerprint,
                "aggregated_sentence_power": aggregated_power,
                "distilled_power_delta": group_delta
            })
        full_results['distillation_by_group'] = distillation_by_group
        self.logger("\n--- Phase 3: Final Analysis Summary ---")
        summary = {
            "description": "The overall emergent meaning, calculated by summing the deltas from each sentence group.",
            "total_sentences": len(all_sentences),
            "sentences_per_group": sentences_per_group,
            "number_of_groups": num_groups,
            "total_distilled_power_delta": total_distilled_power,
            "interpretation": "A positive value indicates net synergistic meaning. A negative value indicates net semantic interference."
        }
        full_results['analysis_summary'] = summary
        self.logger(f"  - Total Distilled Power Delta: {total_distilled_power:.4f}")
        return full_results

    # --- New Starter Drill Methods ---
    def sweep_noise(self, word="love", noise_vals=np.linspace(0, 0.2, 11)):
        """Tests system response to different levels of initial background noise."""
        results = {}
        self.logger("  Noise Level | Total Power")
        self.logger("  -------------------------")
        pattern = self.text_to_binary_image(word, GRID_SIZE, GRID_SIZE)
        for n in noise_vals:
            set_seed(0)
            field = np.random.rand(GRID_SIZE, GRID_SIZE) * n
            fp = self._run_simulation_and_get_fingerprint(field, pattern)
            results[n] = fp['total_power']
            self.logger(f"  {n:<11.4f} | {fp['total_power']:.6e}")
        return results

    def test_bit_flips(self, word="base", n_flips=10):
        """Tests system sensitivity to small changes in the input pattern."""
        results = {}
        self.logger("  Bits Flipped | Total Power")
        self.logger("  -------------------------")
        set_seed(42)
        base_pattern_flat = self.text_to_binary_image(word, GRID_SIZE, GRID_SIZE).flatten()
        for k in range(n_flips + 1):
            pattern_flat = base_pattern_flat.copy()
            if k > 0:
                flip_indices = np.random.choice(len(pattern_flat), k, replace=False)
                pattern_flat[flip_indices] = 1 - pattern_flat[flip_indices]
            
            pattern = pattern_flat.reshape(GRID_SIZE, GRID_SIZE)
            fp = self.get_resonant_fingerprint(pattern)
            results[k] = fp['total_power']
            self.logger(f"  {k:<12} | {fp['total_power']:.6e}")
        return results

    def test_polarity(self, synonyms=("love", "adore", "cherish"), antonyms=("hate", "despise", "loathe")):
        """Compares the resonant power of synonyms vs. antonyms."""
        results = {"synonyms": {}, "antonyms": {}}
        self.logger("  Synonyms:")
        for word in synonyms:
            pattern = self.text_to_binary_image(word, GRID_SIZE, GRID_SIZE)
            fp = self.get_resonant_fingerprint(pattern)
            results["synonyms"][word] = fp
            self.logger(f"    - '{word}': {fp['total_power']:.6e}")

        self.logger("\n  Antonyms:")
        for word in antonyms:
            pattern = self.text_to_binary_image(word, GRID_SIZE, GRID_SIZE)
            fp = self.get_resonant_fingerprint(pattern)
            results["antonyms"][word] = fp
            self.logger(f"    - '{word}': {fp['total_power']:.6e}")
        return results


class Application(tk.Frame):
    """
    The main GUI application for the Semantic Distillation Engine.
    This class handles user interaction, file I/O, and orchestrates the analysis.
    """
    def __init__(self, master=None):
        super().__init__(master)
        self.master = master
        self.master.title("Semantic Distillation Engine V4.0")
        self.master.geometry("800x600")
        self.pack(pady=10, padx=10, fill=tk.BOTH, expand=True)

        # --- Frames for layout ---
        top_frame = tk.Frame(self)
        top_frame.pack(fill=tk.X, pady=5)
        
        control_frame = tk.Frame(self)
        control_frame.pack(fill=tk.X, pady=5)

        middle_frame = tk.Frame(self)
        middle_frame.pack(pady=5, fill=tk.BOTH, expand=True)

        # --- Input Widgets ---
        self.input_type = tk.StringVar(value="File")
        tk.Radiobutton(top_frame, text="From File", variable=self.input_type, value="File").pack(side=tk.LEFT, padx=5)
        tk.Radiobutton(top_frame, text="From URL", variable=self.input_type, value="URL").pack(side=tk.LEFT, padx=5)
        self.input_entry = tk.Entry(top_frame, width=60)
        self.input_entry.pack(side=tk.LEFT, padx=5, fill=tk.X, expand=True)
        tk.Button(top_frame, text="Browse...", command=self.browse_file).pack(side=tk.LEFT)

        # --- Control Widgets ---
        tk.Label(control_frame, text="Sentences per Group:").pack(side=tk.LEFT, padx=(0, 5))
        self.sentences_per_group_entry = tk.Entry(control_frame, width=5)
        self.sentences_per_group_entry.pack(side=tk.LEFT)
        self.sentences_per_group_entry.insert(0, "10")

        tk.Button(control_frame, text="Run Analysis", command=self.run_analysis_thread, font=("Helvetica", 10, "bold")).pack(side=tk.LEFT, padx=20)
        tk.Button(control_frame, text="Run Starter Drills", command=self.run_starter_drills_thread, fg="blue").pack(side=tk.LEFT, padx=10)

        # --- Log Output ---
        self.log_text = scrolledtext.ScrolledText(middle_frame, wrap=tk.WORD, state=tk.DISABLED)
        self.log_text.pack(expand=True, fill=tk.BOTH)

    def log(self, message):
        """Appends a message to the log display, making sure it's thread-safe."""
        def append():
            self.log_text.config(state=tk.NORMAL)
            self.log_text.insert(tk.END, str(message) + "\n")
            self.log_text.see(tk.END)
            self.log_text.config(state=tk.DISABLED)
        self.master.after(0, append)

    def browse_file(self):
        """Opens a file dialog to select a text file."""
        if self.input_type.get() == "File":
            filepath = filedialog.askopenfilename(
                title="Select a Text File",
                filetypes=(("Text files", "*.txt"), ("All files", "*.*"))
            )
            if filepath:
                self.input_entry.delete(0, tk.END)
                self.input_entry.insert(0, filepath)

    def get_content_from_url(self, url):
        """Fetches and cleans text content from a URL using BeautifulSoup."""
        try:
            self.log(f"Fetching content from: {url}")
            headers = {'User-Agent': 'Mozilla/5.0'}
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=10) as response:
                html_content = response.read()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            for script in soup(["script", "style"]):
                script.decompose()
            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = '\n'.join(chunk for chunk in chunks if chunk)
            
            path = urlparse(url).path
            page_name = os.path.splitext(os.path.basename(path))[0]
            if not page_name:
                page_name = urlparse(url).netloc
            
            return text, page_name
        except Exception as e:
            self.log(f"Error fetching URL: {e}")
            return None, None

    def run_analysis_thread(self):
        """Starts the main analysis in a new thread to keep the GUI responsive."""
        thread = threading.Thread(target=self.run_analysis_logic)
        thread.daemon = True
        thread.start()

    def run_starter_drills_thread(self):
        """Starts the starter drills in a new thread."""
        thread = threading.Thread(target=self.run_starter_drills_logic)
        thread.daemon = True
        thread.start()

    def run_analysis_logic(self):
        """The core logic for running the semantic distillation."""
        input_path = self.input_entry.get()
        input_type = self.input_type.get()
        
        if not input_path:
            self.log("Error: Please provide an input file path or URL.")
            return

        try:
            sentences_per_group = int(self.sentences_per_group_entry.get())
            if sentences_per_group <= 0: raise ValueError
        except ValueError:
            self.log("Error: 'Sentences per Group' must be a positive integer.")
            return
            
        output_dir = "analysis_results"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        text_content, input_name = None, "analysis"
        if input_type == "File":
            try:
                with open(input_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()
                input_name = os.path.splitext(os.path.basename(input_path))[0]
            except Exception as e:
                self.log(f"Error reading file: {e}")
                return
        elif input_type == "URL":
            text_content, page_name = self.get_content_from_url(input_path)
            if text_content:
                input_name = re.sub(r'[^a-zA-Z0-9_-]', '_', page_name)
            else:
                return

        if not text_content:
            self.log("Error: Could not retrieve any text content to analyze.")
            return
            
        output_filename = f"{input_name}_distillation_results.json"
        output_filepath = os.path.join(output_dir, output_filename)

        try:
            distillator = SemanticDistillator(logger=self.log)
            results = distillator.run_analysis(text_content, input_path, sentences_per_group)
            
            if results:
                with open(output_filepath, 'w') as f:
                    json.dump(results, f, indent=4)
                self.log(f"\n✓ Process complete. Full results saved to:\n{output_filepath}")
            else:
                self.log("\n✗ Analysis could not be completed.")
        except Exception as e:
            self.log(f"\n--- An unexpected error occurred ---")
            self.log(f"Error details: {e}")
            self.log(traceback.format_exc())

    def run_starter_drills_logic(self):
        """The logic for running the starter drills."""
        self.log("\n" + "="*40)
        self.log("--- Running Starter Drills ---")
        self.log("="*40)
        distillator = SemanticDistillator(logger=self.log)
        
        self.log("\nDrill 1: Noise-level sweep...")
        distillator.sweep_noise()
        
        self.log("\nDrill 2: Bit-flip adversarial test...")
        distillator.test_bit_flips()
        
        self.log("\nDrill 3: Synonym/Antonym Polarity...")
        distillator.test_polarity()
        
        self.log("\n--- Starter Drills Complete ---")


if __name__ == "__main__":
    root = tk.Tk()
    app = Application(master=root)
    app.mainloop()